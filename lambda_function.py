import json
import boto3
import numpy as np
import io
import re
from typing import List, Dict, Tuple

# ---------- Config ----------
bucket_name = "ecommerce-ai-agent-storage"
embeddings_file = "embeddings.npy"
metadata_file = "metadata.json"

embed_model_id = "amazon.titan-embed-text-v2:0"
text_model_id  = "amazon.titan-text-express-v1"  # Ø¥Ø°Ø§ Ø¹Ù†Ø¯Ùƒ :0 Ø§Ø³ØªØ®Ø¯Ù…Ù‡ Ù…Ø«Ù„ "amazon.titan-text-express-v1:0"

TOP_K = 12  # Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø±Ø´Ø­ÙŠÙ† Ù…Ù† Ø§Ù„Ù€ RAG Ù‚Ø¨Ù„ Ø§Ù„ØªØµÙÙŠØ©
FINAL_K = 3 # Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©

s3 = boto3.client("s3")
runtime = boto3.client("bedrock-runtime")

# Cached in the Lambda execution environment
embeddings = None
products = None


# ---------- HTTP response ----------
def make_response(status_code: int, payload: dict) -> dict:
    return {
        "statusCode": status_code,
        "headers": {
            "Content-Type": "application/json; charset=utf-8",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "POST, OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type",
        },
        "body": json.dumps(payload, ensure_ascii=False),
    }


# ---------- Load vectors + metadata ----------
def load_vectors():
    global embeddings, products

    if embeddings is None:
        print("ğŸ“¥ Loading embeddings from S3...")
        npy_data = s3.get_object(Bucket=bucket_name, Key=embeddings_file)["Body"].read()
        embeddings_local = np.load(io.BytesIO(npy_data))
        embeddings_local = embeddings_local.astype(np.float32)
        embeddings_local = np.ascontiguousarray(embeddings_local)
        embeddings_local_norms = np.linalg.norm(embeddings_local, axis=1)
        embeddings_local_norms[embeddings_local_norms == 0] = 1e-12

        # cache both arrays in globals as tuple
        embeddings = (embeddings_local, embeddings_local_norms)
        print(f"âœ… Embeddings loaded: {embeddings_local.shape}")

    if products is None:
        print("ğŸ“„ Loading metadata...")
        meta = s3.get_object(Bucket=bucket_name, Key=metadata_file)["Body"].read()
        products = json.loads(meta)
        print(f"âœ… Products loaded: {len(products)} items")


# ---------- Text helpers ----------
ARABIC_NUM_MAP = str.maketrans("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©", "0123456789")

def normalize_query(q: str) -> str:
    q = (q or "").strip()
    q = q.translate(ARABIC_NUM_MAP)
    return q

def safe_price(p) -> float:
    try:
        if p is None: 
            return float("nan")
        return float(p)
    except:
        return float("nan")

def extract_budget(query: str) -> float:
    """
    Examples:
      "ØªØ­Øª 200" "Ø§Ù‚Ù„ Ù…Ù† 300" "under 150"
    """
    q = query.lower()
    m = re.search(r"(?:ØªØ­Øª|Ø§Ù‚Ù„ Ù…Ù†|Ø£Ù‚Ù„ Ù…Ù†|under|less than)\s*(\d+(?:\.\d+)?)", q)
    if m:
        return float(m.group(1))
    # fallback: any number (weak)
    m2 = re.search(r"(\d+(?:\.\d+)?)", q)
    return float(m2.group(1)) if m2 else float("nan")


# ---------- Intent detection ----------
def detect_intent(query: str) -> str:
    q = query.lower()

    if any(w in q for w in ["Ù‚Ø§Ø±Ù†", "Ù…Ù‚Ø§Ø±Ù†Ø©", "ÙØ±Ù‚", "Ø§Ù„ÙØ±Ù‚", "compare", "versus", "vs", "Ø§ÙØ¶Ù„ Ù…Ù†"]):
        return "COMPARE"

    if any(w in q for w in ["Ø£ØºÙ„Ù‰", "Ø§Ù„Ø§ØºÙ„Ù‰", "Ø§ØºÙ„Ù‰", "most expensive", "highest price"]):
        return "MAX_PRICE"

    if any(w in q for w in ["Ø£Ø±Ø®Øµ", "Ø§Ù„Ø§Ø±Ø®Øµ", "Ø§Ø±Ø®Øµ", "cheapest", "lowest price"]):
        return "MIN_PRICE"

    if any(w in q for w in ["ØªØ­Øª", "Ø§Ù‚Ù„ Ù…Ù†", "Ø£Ù‚Ù„ Ù…Ù†", "under", "less than"]):
        return "BUDGET"

    return "RECOMMEND"


# ---------- Embedding ----------
def embed_query(text: str) -> np.ndarray:
    response = runtime.invoke_model(
        modelId=embed_model_id,
        contentType="application/json",
        accept="application/json",
        body=json.dumps({"inputText": text}),
    )
    output = json.loads(response["body"].read())
    vec = np.array(output["embedding"], dtype=np.float32)
    return vec


# ---------- RAG retrieval ----------
def cosine_topk(user_vec: np.ndarray, top_k: int) -> List[Tuple[int, float]]:
    emb_matrix, emb_norms = embeddings
    u_norm = float(np.linalg.norm(user_vec))
    if u_norm == 0:
        u_norm = 1e-12

    scores = (emb_matrix @ user_vec) / (emb_norms * u_norm)
    # handle any NaNs
    scores = np.nan_to_num(scores, nan=-1.0, posinf=-1.0, neginf=-1.0)

    idx = np.argpartition(scores, -top_k)[-top_k:]
    idx = idx[np.argsort(scores[idx])[::-1]]
    return [(int(i), float(scores[i])) for i in idx]


# ---------- Filters ----------
def is_perfume_query(q: str) -> bool:
    ql = q.lower()
    return ("Ø¹Ø·Ø±" in ql) or ("perfume" in ql) or ("fragrance" in ql)

def filter_candidates(query: str, candidates: List[Dict]) -> List[Dict]:
    q = query.lower()

    # Category hint
    if is_perfume_query(q):
        filtered = []
        for p in candidates:
            cat = (p.get("category") or "").strip()
            tags = " ".join(p.get("tags", []) or [])
            if cat == "Ø¹Ø·ÙˆØ±" or ("Ø¹Ø·Ø±" in tags):
                filtered.append(p)
        candidates = filtered or candidates

    # Budget
    budget = extract_budget(query)
    if not np.isnan(budget):
        under = []
        for p in candidates:
            pr = safe_price(p.get("price"))
            if not np.isnan(pr) and pr <= budget:
                under.append(p)
        candidates = under or candidates

    return candidates


# ---------- Better selection logic ----------
def pick_products(intent: str, query: str, scored: List[Tuple[Dict, float]]) -> List[Dict]:
    """
    scored: list of (product_dict, similarity_score)
    returns selected products (FINAL_K or 1) with a tiny bit of reasoning logic
    """
    # Attach score for later prompt/debug
    enriched = []
    for p, s in scored:
        p2 = dict(p)
        p2["_score"] = round(float(s), 4)
        p2["_price"] = safe_price(p.get("price"))
        enriched.append(p2)

    # filter with rules
    candidates = filter_candidates(query, enriched)
    # keep their scores
    # (candidates already include _score/_price)
    valid_price = [p for p in candidates if not np.isnan(p["_price"])]

    if intent == "MAX_PRICE":
        if valid_price:
            best = max(valid_price, key=lambda x: x["_price"])
            return [best]
        return candidates[:1] if candidates else []

    if intent == "MIN_PRICE":
        if valid_price:
            best = min(valid_price, key=lambda x: x["_price"])
            return [best]
        return candidates[:1] if candidates else []

    if intent == "BUDGET":
        # Under budget: prioritize relevance first, then cheaper among top
        candidates_sorted = sorted(candidates, key=lambda x: (-x["_score"], x["_price"] if not np.isnan(x["_price"]) else 1e9))
        return candidates_sorted[:FINAL_K]

    if intent == "COMPARE":
        # return more items for comparison (up to 4)
        candidates_sorted = sorted(candidates, key=lambda x: -x["_score"])
        return candidates_sorted[:min(4, max(2, FINAL_K+1))]

    # RECOMMEND:
    # combine relevance + mild preference for reasonable price if present
    candidates_sorted = sorted(
        candidates,
        key=lambda x: (
            -x["_score"],
            x["_price"] if not np.isnan(x["_price"]) else 1e9
        )
    )
    return candidates_sorted[:FINAL_K]


# ---------- LLM context + prompting ----------
def compact_product_line(p: Dict) -> str:
    name = p.get("name", "")
    cat = p.get("category", "")
    price = p.get("price", "")
    desc = (p.get("description") or "").strip()
    tags = p.get("tags", [])
    tags_txt = "ØŒ ".join(tags[:6]) if isinstance(tags, list) else ""
    return (
        f"- Ø§Ù„Ø§Ø³Ù…: {name}\n"
        f"  Ø§Ù„ÙØ¦Ø©: {cat}\n"
        f"  Ø§Ù„Ø³Ø¹Ø±: {price} Ø±ÙŠØ§Ù„\n"
        f"  Ø§Ù„ÙˆØ³ÙˆÙ…: {tags_txt}\n"
        f"  Ø§Ù„ÙˆØµÙ: {desc}\n"
        f"  (Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {p.get('_score','')})"
    )

def build_context_for_llm(selected: List[Dict]) -> str:
    return "\n\n".join([compact_product_line(p) for p in selected])

def llm_generate_answer(query: str, intent: str, selected: List[Dict]) -> str:
    context_text = build_context_for_llm(selected)

    # Instructions vary by intent
    if intent == "COMPARE":
        task = (
            "Ù‚Ø¯Ù‘Ù… Ù…Ù‚Ø§Ø±Ù†Ø© ÙˆØ§Ø¶Ø­Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…Ù†ØªØ¬Ø§ØªØŒ ÙˆØ§Ø°ÙƒØ± Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ´Ø§Ø¨Ù‡ ÙˆØ§Ù„Ø§Ø®ØªÙ„Ø§Ù (Ø§Ù„Ø±Ø§Ø¦Ø­Ø©/Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…/Ø§Ù„Ø·Ø§Ø¨Ø¹/Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø³Ø¹Ø±). "
            "Ø§Ø®ØªÙ… Ø¨ØªÙˆØµÙŠØ©: Ù„Ù…Ù† ÙŠÙ†Ø§Ø³Ø¨ ÙƒÙ„ Ù…Ù†ØªØ¬."
        )
    elif intent == "MAX_PRICE":
        task = "Ø£Ø¬Ø¨ Ø¨ÙˆØ¶ÙˆØ­ Ø¹Ù† Ø£ØºÙ„Ù‰ Ø®ÙŠØ§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø¶Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŒ ÙˆØ§Ø°ÙƒØ± Ù„Ù…Ø§Ø°Ø§ Ù‚Ø¯ ÙŠØ³ØªØ­Ù‚ Ø§Ù„Ø³Ø¹Ø±ØŒ ÙˆØ§Ù‚ØªØ±Ø­ Ø¨Ø¯ÙŠÙ„ÙŠÙ† Ø£Ø±Ø®Øµ Ù…Ø¹ Ø³Ø¨Ø¨."
    elif intent == "MIN_PRICE":
        task = "Ø£Ø¬Ø¨ Ø¨ÙˆØ¶ÙˆØ­ Ø¹Ù† Ø£Ø±Ø®Øµ Ø®ÙŠØ§Ø± Ù…Ù†Ø§Ø³Ø¨ Ø¶Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŒ ÙˆØ§Ø°ÙƒØ± ØªÙ†Ø§Ø²Ù„Ø§ØªÙ‡ Ø¥Ù† ÙˆØ¬Ø¯ØªØŒ ÙˆØ§Ù‚ØªØ±Ø­ Ø¨Ø¯ÙŠÙ„ÙŠÙ† Ø£Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø©/Ø³Ø¹Ø± Ù…Ø¹ Ø³Ø¨Ø¨."
    elif intent == "BUDGET":
        task = "Ø§Ø®ØªØ± Ø£ÙØ¶Ù„ Ø®ÙŠØ§Ø±Ø§Øª Ø¶Ù…Ù† Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø©ØŒ ÙˆØ§Ø°ÙƒØ± Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ØŒ Ù…Ø¹ Ø¥Ø¨Ø±Ø§Ø² Ø§Ù„Ù…ÙØ§Ø¶Ù„Ø§Øª."
    else:
        task = "Ù‚Ø¯Ù‘Ù… ØªÙˆØµÙŠØ§Øª Ù…Ø±ØªØ¨Ø© Ù…Ù† Ø§Ù„Ø£ÙØ¶Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ØŒ Ù…Ø¹ Ø£Ø³Ø¨Ø§Ø¨ Ø¹Ù…Ù„ÙŠØ© Ù…Ø®ØªØµØ±Ø© ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ø³Ø±ÙŠØ¹Ø© Ø¨ÙŠÙ† Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª."

    prompt = f"""
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ØªØ³ÙˆÙ‚ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø°ÙƒÙŠ Ù„Ù…ØªØ¬Ø± Ø³Ø¹ÙˆØ¯ÙŠ.
Ù…Ù‡Ù…ØªÙƒ: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (RAG) ÙÙ‚Ø·. Ù„Ø§ ØªØ®ØªØ±Ø¹ Ù…Ù†ØªØ¬Ø§Øª.

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{query}

Ù†ÙŠØ© Ø§Ù„Ø³Ø¤Ø§Ù„ (Ù„Ù„Ø§Ø³ØªØ±Ø´Ø§Ø¯):
{intent}

Ù…Ù†ØªØ¬Ø§Øª Ù…Ø³ØªØ±Ø¬Ø¹Ø© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
{context_text}

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
- Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„ÙˆØ§Ø¶Ø­Ø©ØŒ Ø¬Ù…Ù„ Ù…Ù…ØªØ§Ø²Ø© ÙˆØ³Ù„Ø³Ø©.
- {task}
- Ù„Ø§ ØªØ°ÙƒØ± "Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡" Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù….
- Ø¥Ù† ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± ÙƒØ§ÙÙŠØ©ØŒ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø· Ù‚Ø¨Ù„ Ø§Ù„ØªÙˆØµÙŠØ©.

Ø§Ù„Ø¬ÙˆØ§Ø¨:
"""

    response = runtime.invoke_model(
        modelId=text_model_id,
        contentType="application/json",
        accept="application/json",
        body=json.dumps({
            "inputText": prompt,
            "textGenerationConfig": {
                "maxTokenCount": 450,
                "temperature": 0.4,
                "topP": 0.9,
            }
        }),
    )
    body = json.loads(response["body"].read())
    return body["results"][0]["outputText"].strip()


# ---------- Main Lambda handler ----------
def lambda_handler(event, context):
    # CORS preflight
    request_method = event.get("requestContext", {}).get("http", {}).get("method", "")
    if request_method == "OPTIONS":
        return {
            "statusCode": 200,
            "headers": {
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Methods": "POST, OPTIONS",
                "Access-Control-Allow-Headers": "Content-Type",
            },
            "body": ""
        }

    try:
        load_vectors()

        body = event.get("body", "{}")
        if isinstance(body, str):
            try:
                body = json.loads(body)
            except json.JSONDecodeError:
                return make_response(400, {"error": "Invalid JSON body", "rawBody": body})

        query = normalize_query(body.get("query", ""))
        if not query:
            return make_response(400, {"error": "query required"})

        intent = detect_intent(query)

        # 1) RAG retrieval by embeddings
        user_vec = embed_query(query)
        top_pairs = cosine_topk(user_vec, TOP_K)  # list of (idx, score)

        scored_products = []
        for idx, score in top_pairs:
            if 0 <= idx < len(products):
                scored_products.append((products[idx], score))

        if not scored_products:
            return make_response(200, {"query": query, "answer": "Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ù…Ù†ØªØ¬ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø·Ù„Ø¨.", "products": []})

        # 2) Select final products using intent-aware logic
        selected = pick_products(intent, query, scored_products)

        if not selected:
            return make_response(200, {"query": query, "answer": "Ù„Ù… Ø£Ø¬Ø¯ Ø£ÙŠ Ù…Ù†ØªØ¬ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø·Ù„Ø¨.", "products": []})

        # 3) LLM answer (compare/contrast + good sentences)
        answer = llm_generate_answer(query, intent, selected)

        # Remove internal fields before returning products to UI (optional)
        public_products = []
        for p in selected:
            p_out = dict(p)
            p_out.pop("_score", None)
            p_out.pop("_price", None)
            public_products.append(p_out)

        return make_response(200, {
            "query": query,
            "intent": intent,
            "answer": answer,
            "products": public_products
        })

    except Exception as e:
        print("ğŸ”¥ ERROR in Lambda:", repr(e))
        return make_response(500, {"error": str(e)})
